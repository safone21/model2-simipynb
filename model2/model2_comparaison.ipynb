{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whdL9rvv1Dal"
      },
      "source": [
        "# Reaction Time Prediction Model - Model Comparison\n",
        "\n",
        "## Objective\n",
        "Predict human reaction time (PVT test) based on physiological and lifestyle factors.\n",
        "\n",
        "**Dataset**: 64 samples, 7 original features (Gender, Sleep, Heart rate, Caffeine, O2 saturation, Stress, Age)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyzWts6x1Dan"
      },
      "source": [
        "## 1. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r26IqWQJ1Dao"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.model_selection import LeaveOneOut, cross_val_predict\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opN5ndXF1Dao"
      },
      "source": [
        "## 2. Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "G0d2scsh1Dap"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv('Expérience 2 - Feuil1.csv')\n",
        "\n",
        "# Remove unnecessary columns\n",
        "df = df.drop(['GLUCOSE (mg/dL)', 'PARTICIPANT'], axis=1)\n",
        "\n",
        "# Encode gender (H=1, F=0)\n",
        "le = LabelEncoder()\n",
        "df['SEXE'] = le.fit_transform(df['SEXE'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2rUgL8f1Dap"
      },
      "source": [
        "## 3. Feature Engineering\n",
        "\n",
        "Create new features by combining existing ones to capture interactions and non-linear relationships.\n",
        "\n",
        "### Why These Features?\n",
        "\n",
        "**1. SLEEP_STRESS = Sleep × Stress**\n",
        "- **Combined effect**: Low sleep + high stress is worse\n",
        "- **Expected**: More sleep with high stress = better RT; Less sleep with high stress = worse RT\n",
        "\n",
        "**2. HEART_STRESS = Heart Rate × Stress**\n",
        "- **Expected**: High heart rate + high stress Could improve RT (alertness) OR worsen it (anxiety)\n",
        "\n",
        "**3. AGE_SLEEP = Age × Sleep**\n",
        "- **Age-dependent sleep effect**: Older people need quality sleep more than younger people\n",
        "- **Expected**: Young + low sleep = less impact; Old + low sleep = bigger impact\n",
        "\n",
        "**4. CAFFEINE_SLEEP = Caffeine ÷ (Sleep + 1)**\n",
        "    (+1)To prevent division by zero if sleep hours = 0.\n",
        "\n",
        "- **Compensatory behavior**: People use caffeine to compensate for poor sleep\n",
        "- **Relative dependency**: 200mg caffeine after 4h sleep ≠ 200mg after 8h sleep\n",
        "- **Expected**: High ratio = trying to compensate for tiredness\n",
        "\n",
        "**5. SLEEP_SQ = Sleep²**\n",
        "- **Diminishing returns**: 8h→9h sleep improvement ≠ 4h→5h improvement\n",
        "- **Non-linear relationship**: Sleep doesn't affect RT linearly\n",
        "\n",
        "**6. AGE_SQ = Age²**\n",
        "- **Non-linear aging**: RT decline accelerates with age (not constant)\n",
        "- **Expected**: 20→30 age change ≠ 40→50 age change in RT impact\n",
        "\n",
        "**7. STRESS_SQ = Stress²**\n",
        "- **Exponential impact**: Moderate stress (30%) ≠ 2× impact of high stress (60%)\n",
        "\n",
        "**8. SLEEP_DEFICIT = 1 if Sleep < 7, else 0**\n",
        "- **Clinical threshold**: 7 hours is recommended minimum\n",
        "- **Binary switch**: There's a \"cliff\" effect below 7h\n",
        "- **Expected**: People with <7h sleep are in a different performance category\n",
        "\n",
        "**9. HIGH_STRESS = 1 if Stress > 40%, else 0**\n",
        "- **Threshold effect**: Moderate stress (20-40%) ≠ high stress (>40%)\n",
        "- **Clinical relevance**: >40% biological stress is considered elevated\n",
        "- **Categorization**: Separates \"stressed\" from \"not stressed\" individuals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mJhkLRj11Daq"
      },
      "outputs": [],
      "source": [
        "# Create interaction and polynomial features\n",
        "df['SLEEP_STRESS'] = df['SOMMEIL (H)'] * df['STRESS BIOLOGIQUE %']\n",
        "df['HEART_STRESS'] = df['HEART RATE (BPM)'] * df['STRESS BIOLOGIQUE %']\n",
        "df['AGE_SLEEP'] = df['AGE'] * df['SOMMEIL (H)']\n",
        "df['CAFFEINE_SLEEP'] = df['CAFFEINE (mg)'] / (df['SOMMEIL (H)'] + 1)\n",
        "df['SLEEP_SQ'] = df['SOMMEIL (H)'] ** 2\n",
        "df['AGE_SQ'] = df['AGE'] ** 2\n",
        "df['STRESS_SQ'] = df['STRESS BIOLOGIQUE %'] ** 2\n",
        "df['SLEEP_DEFICIT'] = np.where(df['SOMMEIL (H)'] < 7, 1, 0)\n",
        "df['HIGH_STRESS'] = np.where(df['STRESS BIOLOGIQUE %'] > 40, 1, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggfac2JS1Daq"
      },
      "source": [
        "## 4. Prepare Features and Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "z2Y99tgA1Daq"
      },
      "outputs": [],
      "source": [
        "# Separate X and y\n",
        "X = df.drop('PVT : TEMPS DE REACTION (ms)', axis=1)\n",
        "y = df['PVT : TEMPS DE REACTION (ms)']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogvsWQTT1Dar"
      },
      "source": [
        "## 5. Evaluation Metrics Explanation\n",
        "\n",
        "### 1. MAE (Mean Absolute Error)\n",
        "**Formule:**\n",
        "$$MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$$\n",
        "\n",
        "**Interprétation:**\n",
        "- Mesure l'erreur moyenne absolue entre les valeurs prédites et réelles\n",
        "- **Plus le MAE est faible, meilleur est le modèle**\n",
        "- Unité: même unité que la variable cible (ms dans notre cas)\n",
        "- **Bon résultat:** MAE < 10% de la moyenne de la variable cible\n",
        "\n",
        "### 2. R² (Coefficient de détermination)\n",
        "**Formule:**\n",
        "$$R^2 = 1 - \\frac{\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}$$\n",
        "\n",
        "**Interprétation:**\n",
        "- Mesure la proportion de variance expliquée par le modèle\n",
        "- **Plage:** -∞ à 1 (négatif = très mauvais, 0 = modèle naïf, 1 = parfait)\n",
        "- **Plus le R² est proche de 1, meilleur est le modèle**\n",
        "- **Bon résultat:**\n",
        "  - R² > 0.7 = Bon modèle\n",
        "  - R² > 0.8 = Très bon modèle\n",
        "  - R² > 0.9 = Excellent modèle\n",
        "\n",
        "### 3. MRE (Mean Relative Error)\n",
        "**Formule:**\n",
        "$$MRE = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{|y_i - \\hat{y}_i|}{y_i} \\times 100$$\n",
        "\n",
        "**Interprétation:**\n",
        "- Mesure l'erreur relative moyenne en pourcentage\n",
        "- **Plus le MRE est faible, meilleur est le modèle**\n",
        "- **Bon résultat:**\n",
        "  - MRE < 5% = Excellent\n",
        "  - MRE < 10% = Très bon\n",
        "  - MRE < 15% = Acceptable\n",
        "  - MRE > 20% = Nécessite amélioration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ahsn_AGe1Dar"
      },
      "source": [
        "## 6. Train Models with Leave-One-Out Cross-Validation\n",
        "\n",
        "### Validation: Leave-One-Out CV\n",
        "- Uses maximum data (trains on 63, tests on 1, repeats 64 times)\n",
        "- Most reliable for small datasets\n",
        "\n",
        "We will compare 4 models:\n",
        "1. **ElasticNet** - Linear model with regularization\n",
        "2. **Gradient Boosting** - Ensemble of decision trees\n",
        "3. **Random Forest** - Parallel ensemble of trees\n",
        "4. **XGBoost** - Optimized gradient boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xZDP-N651Dar"
      },
      "outputs": [],
      "source": [
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Dictionary to store results\n",
        "results = {}\n",
        "loo = LeaveOneOut()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKcaeR6r1Dar"
      },
      "source": [
        "### Model 1: ElasticNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmHkHUdl1Dar",
        "outputId": "e7df9965-aa94-44c9-e97a-3ec4ab76ae7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Training ElasticNet...\n",
            "============================================================\n",
            "MAE: 33.3544\n",
            "R²:  0.0428\n",
            "MRE: 8.6011%\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"Training ElasticNet...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create and train model\n",
        "elastic_model = ElasticNet(alpha=1, l1_ratio=0.5, max_iter=10000, random_state=42)\n",
        "y_pred_elastic = cross_val_predict(elastic_model, X_scaled, y, cv=loo)\n",
        "\n",
        "# Calculate metrics\n",
        "mae_elastic = mean_absolute_error(y, y_pred_elastic)\n",
        "r2_elastic = r2_score(y, y_pred_elastic)\n",
        "mre_elastic = np.mean(np.abs((y - y_pred_elastic) / y)) * 100\n",
        "\n",
        "# Train final model on all data\n",
        "elastic_model.fit(X_scaled, y)\n",
        "\n",
        "results['ElasticNet'] = {'MAE': mae_elastic, 'R²': r2_elastic, 'MRE (%)': mre_elastic}\n",
        "print(f\"MAE: {mae_elastic:.4f}\")\n",
        "print(f\"R²:  {r2_elastic:.4f}\")\n",
        "print(f\"MRE: {mre_elastic:.4f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMM6ldid1Dar"
      },
      "source": [
        "### Model 2: Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB1zOZIl1Das",
        "outputId": "afe43b7e-a681-4e1d-d58d-d84876ff0765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training Gradient Boosting Regressor...\n",
            "============================================================\n",
            "MAE: 36.0774\n",
            "R²:  0.0325\n",
            "MRE: 9.3593%\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Training Gradient Boosting Regressor...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "gb_model = GradientBoostingRegressor(\n",
        "    n_estimators=120,\n",
        "    max_depth=4,\n",
        "    learning_rate=0.09,\n",
        "    subsample=0.8,\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=4,\n",
        "    loss='huber',\n",
        "    alpha=0.9,\n",
        "    random_state=123\n",
        ")\n",
        "\n",
        "y_pred_gb = cross_val_predict(gb_model, X_scaled, y, cv=loo)\n",
        "\n",
        "mae_gb = mean_absolute_error(y, y_pred_gb)\n",
        "r2_gb = r2_score(y, y_pred_gb)\n",
        "mre_gb = np.mean(np.abs((y - y_pred_gb) / y)) * 100\n",
        "\n",
        "gb_model.fit(X_scaled, y)\n",
        "\n",
        "results['Gradient Boosting'] = {'MAE': mae_gb, 'R²': r2_gb, 'MRE (%)': mre_gb}\n",
        "print(f\"MAE: {mae_gb:.4f}\")\n",
        "print(f\"R²:  {r2_gb:.4f}\")\n",
        "print(f\"MRE: {mre_gb:.4f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0qlXKd61Das"
      },
      "source": [
        "### Model 3: Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNhZ02kA1Das",
        "outputId": "61f3abfb-3a24-42b5-c9b9-35440f2c96bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training Random Forest Regressor...\n",
            "============================================================\n",
            "MAE: 35.9991\n",
            "R²:  -0.0289\n",
            "MRE: 9.3207%\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Training Random Forest Regressor...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=120,\n",
        "    max_depth=10,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=123,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "y_pred_rf = cross_val_predict(rf_model, X_scaled, y, cv=loo)\n",
        "\n",
        "mae_rf = mean_absolute_error(y, y_pred_rf)\n",
        "r2_rf = r2_score(y, y_pred_rf)\n",
        "mre_rf = np.mean(np.abs((y - y_pred_rf) / y)) * 100\n",
        "\n",
        "rf_model.fit(X_scaled, y)\n",
        "\n",
        "results['Random Forest'] = {'MAE': mae_rf, 'R²': r2_rf, 'MRE (%)': mre_rf}\n",
        "print(f\"MAE: {mae_rf:.4f}\")\n",
        "print(f\"R²:  {r2_rf:.4f}\")\n",
        "print(f\"MRE: {mre_rf:.4f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HtlQ7RX1Das"
      },
      "source": [
        "### Model 4: XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtcNu3xw1Das",
        "outputId": "4ab7853c-e75c-4f94-d7cf-8e8e044e235c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Training XGBoost Regressor...\n",
            "============================================================\n",
            "MAE: 38.6688\n",
            "R²:  -0.2197\n",
            "MRE: 10.1461%\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Training XGBoost Regressor...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "xgb_model = XGBRegressor(\n",
        "    n_estimators=120,\n",
        "    max_depth=4,\n",
        "    learning_rate=0.09,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=123,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "y_pred_xgb = cross_val_predict(xgb_model, X_scaled, y, cv=loo)\n",
        "\n",
        "mae_xgb = mean_absolute_error(y, y_pred_xgb)\n",
        "r2_xgb = r2_score(y, y_pred_xgb)\n",
        "mre_xgb = np.mean(np.abs((y - y_pred_xgb) / y)) * 100\n",
        "\n",
        "xgb_model.fit(X_scaled, y)\n",
        "\n",
        "results['XGBoost'] = {'MAE': mae_xgb, 'R²': r2_xgb, 'MRE (%)': mre_xgb}\n",
        "print(f\"MAE: {mae_xgb:.4f}\")\n",
        "print(f\"R²:  {r2_xgb:.4f}\")\n",
        "print(f\"MRE: {mre_xgb:.4f}%\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}